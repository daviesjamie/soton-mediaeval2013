\documentclass{../acm_proc_article-me11_tweaked}
\usepackage{url}
\usepackage{paralist}
\usepackage[numbers]{natbib}
\usepackage{mathptmx}

\setlength{\parskip}{0cm}
\setlength{\parindent}{1em}
\def\newblock{\hskip .11em plus .33em minus .07em}
\begin{document}
\conferenceinfo{\textit{MediaEval 2013 Workshop,}}{October 18-19, 2013, Barcelona, Spain}

\title{Social Event Detection via sparse multi-modal feature selection and incremental density based clustering methods}

%
\def\sharedaffiliation{%
\end{tabular}
\begin{tabular}{c}}
%

\numberofauthors{4}
\author{
% 1st. author
\alignauthor
Sina Samangooei\\
       \email{ss@ecs.soton.ac.uk}
% 2nd. author
\alignauthor
Jonathon S. Hare\\
       \email{jsh2@ecs.soton.ac.uk}
% 3rd. author
\alignauthor
David P. Dupplaw\\
			\email{dpd@ecs.soton.ac.uk}
% 4th. author
\and
\alignauthor
Paul H. Lewis\\
       \email{phl@ecs.soton.ac.uk}
\sharedaffiliation
       \affaddr{Electronics and Computer Science, University of Southampton, United Kingdom}
}

\maketitle
\begin{abstract}
Combining items from social media streams, such as flickr photos and twitter tweets, into meaningful groups can help users contextualize and effectively consume the torrents of information now made available on the social web. This task is made challenging due to the scale of the streams and the inherently multimodal nature of the information to be contextualized. Such unsupervised clustering tasks are fundamentally ill-posed and application specific questions. A fundamental question in such multimodal contexts is which features best signify that two items should belong to the same grouping. We present a methodology which approaches social event detection as a multi-modal clustering task. We address the various challenges of this task, including: the selection of the features used to compare items to one another; the construction of a single sparse affinity matrix, combining the features, their relative importance considered and finally clustering techniques which produce meaningful item groups and which can scale to cluster the large number of items present in this task. In our best tested configuration we achieve an F1 score of 0.94, showing that a good compromise between precision and recall of clusters can be achieved using our technique.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{}

\keywords{}
\begin{table*}[t!]
\centering
    \begin{tabular}{l|l|l|l|l}
    ~                  & \textbf{DBSCAN (best)} &  \textbf{Spectral (best)} & \textbf{DBSCAN (average)} & \textbf{Spectral (average)} \\
    \hline
    \hline
    \textbf{F1}                 & 0.9454        & 0.9114           & 0.9461           & 0.9024             \\
    % \hline
    % \textbf{NMI}                & 0.9851        & 0.9765           & 0.9852           & 0.9737             \\
    % \hline
    % \textbf{F1 (Div)}           & 0.9350        & 0.8819           & 0.9358           & 0.8663             \\
    % \hline
    % \textbf{Random Baseline F1} & 0.0589        & 0.0580           & 0.0597           & 0.0569             \\
    % \hline
    % \textbf{Div F1}             & 0.8865        & 0.8534           & 0.8864           & 0.8455             \\
    \end{tabular}
\end{table*}
\section{Introduction}
In their June 2013 WWDC keynote, Apple announced a new photo collection feature for their iOS mobile operating system. With the evocative tag-line ``Life is full of special moments. So is your photo library'' Apple note the importance of clustering social streams by their belonging to some real life event. This, along with the plethora of mobile and desktop applications which offer some degree of event detection in user photo streams, demonstrates that detecting events in multimedia streams has real practical utility for users. If detection and clustering by events within private collections is useful, detecting events and clustering items in a multi-user social media context must also have practical benefits. Within this context, challenges of scale and feature error inherent in non-curated collections must be addressed to create meaningful groupings of social media artifacts which afford the user with the ability better understand, consume and contextualize social streams. 

In this short document we present our approach to achieving clustering of social media artifacts towards addressing task 1 in the Social Event Detection (SED) challenge of the Mediaeval 2013 multimedia evaluation. Task 1 asks that a collection of flickr photos be organised into events such that events are defined as ``events that are planned by people, attended by people and the media illustrating the events are captured by people''. The flickr items in this task contain metadata beyond the content of the image itself. Namely, the flickr photos are guaranteed to include accurate: flickrids, user ids and time posted. The photos may also contain in varying degrees of accuracy location information, time taken according to the camera, and textual information including title, tags and a description. 

% Our approach to this task is comprised of \begin{inparaenum}[\itshape1\upshape)]
% \item an initial similar event step using a fast inverted index;
% \item custom feature and distance metrics along with a custom weighting scheme used to construct a sparse affinity matrix;
% \item exploration of two clustering techniques which cluster events using this affinity matrix, namely DBSCAN and spectral clustering;
% \item development of an incremental event clustering technique which allow the clustering techniques used to scale
% \end{inparaenum}. These steps will be described in more detail in the following sections.

\section{Methodology} % (fold)
\label{sec:methodology}

\subsection{Affinity Matrix Filter} % (fold)
\label{sub:lucene_filter}
The overarching strategy of our technique is the construction of a square sparse affinity matrix whose elements represent the similarity of two items of social media. Once this object is created, two clustering algorithms are applied. However, the creation of such a matrix for any number of items beyond a trivial number is a time consuming $O(n^2)$ operation which scales poorly. Therefore, the first stage of our process was the efficient construction of such an affinity matrix. 

Given the SED2013 training set we know for $~300,000$ objects there exist $~14,000$ clusters. The average number of items per cluster in the training set is $20$. From this information we know that the similarity between most objects must be 0 if similarity is a reasonable indication of cluster membership. However, inducing this sparsity after feature extraction and comparison of the social media objects is without merit as the expensive operation is still performed, only forced to 0 after this fact. To address this issue, we construct a Lucene~\footnote{\url{http://lucene.apache.org/core/}} index of the items to be clustered. Then, for each item in the dataset we construct a custom Lucene query, receiving an artificially limited number of documents. We then extract features and compare distances using only the documents returned by this query. Once the work is done to construct this lucene index, this operation has a complexity of $O(n)$ which allows a much faster construction of the affinity matrix.
% subsection lucene_filter (end)

\subsection{Multi-modal Affinity} % (fold)
\label{ssub:multi_modal_affinity}
Once documents are filtered using lucene, the affinity matrix is constructed. The items being clustered are inherently multi-modal. These modalities include time information (both posted and taken), geo graphic information, textual information (tags, descriptions and titles) as well as the visual information of the flickr photos themselves. Any of these modalities might serve as a strong signal of cluster membership. Photos taken in the same place, or at the same time, or containing similar text might all serve as strong indication of these photos being of the same event. However on their own the features might also serve to confuse unrelated events, for example, two events happening on a Friday, but one in Nottingham and one in London. Therefore, the first stage in the construction of a unified affinity matrix is a separate affinity matrix for each of these features, while the second step is the correct combination of the affinity matrices. Inspired by~\citet{Reuter2012ECS23247962324824} we use a logarithmic distance function for our two time features. We also use a logarithmic distance function for our geographic haversine based distance function. Fundamentally, this forces distances and times beyond a certain distance to count as being infinitely far, or as having 0 similarity. For the textual features we use the TF-IDF score with the IDF statistics calculated against the entire corpus of flickr objects. We also experimented with an LSH based visual feature for image feature affinity matrix construction. However, we found this feature only made F1 scores worse in the training set and the visual features were completely ignored in all submitted runs against the test set. If any given feature is missing or empty for either object represented by a particular cell in the affinity matrix, for the purpose of the sparse affinity matrix it is treated as being ``not present'' rather than 0 similarity. The distinction here is important for how these affinity matrices are combined.

Once the per-modality affinity matrices were constructed, we experimented with various feature-fusion techniques to combine them. Combination schemes including: product, max, min, and average were tested, average was shown to work well. Different feature weightings were also investigated. To calculate the combined affinity $w_{ij}$ of the $i^{th}$ image with the $j^{th}$ image, the feature affinities $w_{ij}^{(f)}$ for all features $f\in F_{ij}$ were used where $F_{ij}$ is all the features which had values for both images $i$ and $j$, i.e. those features ``present'' in the affinity matrix:
\begin{eqnarray}
 w_{ij} = \sum\limits_{f}^F p^{(f)} w_{ij}^{(f)}&,&\sum\limits_{f}^F p^{(f)} = 1
\end{eqnarray}
where $p^{(f)}$ is the weight of a given feature $f$. The final affinity matrix produced by this process was used by the clustering techniques below.

% subsubsection multi_modal_affinity (end)

\subsection{Event Clustering} % (fold)
\label{sub:event_clustering}

The exact number of events in a corpus was unknown and hard to estimate, we explored clustering techniques which work without an explicit $k$. The first technique we experimented with was a modified version of the classic Density-Based Spatial Clustering of Applications with Noise  (DBSCAN) algorithm, implementing a fast version of the neighborhood selection stage which worked against sparse affinity matrices. Secondly, we explored more sophisticated spectral clustering techniques, interpreting the affinity matrix as weights of edges on a graph and uses graph theoretic techniques to automatically estimate the number of clusters present in the graph. The data items are projected into a metric space which ensures better separation between the clusters. We used a classic cosine similarity nearest neighbour DBSCAN to cluster in the spectral space. 

% Spectral clustering requires the eigen decomposition of the laplacian of the affinity matrix, a calculation which quickly becomes intractable beyond $100,000$ items. Our sparse matrix DBSCAN is a relatively efficient algorithm and can easily cluster the number of items in the SED2013 challenge in memory. However, even DBSCAN has limits in terms of performance, its unmodified form requiring the entire space's affinity matrix to be held in memory, this could eventually become intractable to hold.
In response to challenges of scale that both DBSCAN and Spectral clustering methods face given enough data, we developed a general incremental clustering technique which takes advantage of the streaming nature of social media data. Namely, if we assume the data appears in an incremental fashion, we can cluster the data in small windows. If we then allow the windows to grow and perform the clustering again, we might notice that certain clusters and their members are stable across window growth. This stability could be defined as the cluster members not changing whatsoever, or a relaxed form could define stability as paired clusters with high overlap. Regardless, once a cluster is defined as stable those items could be removed and not involved in the next window size increase. In this way, the effective number of items to be clustered in any given round will increase as items arrive but will also decrease as clusters become stable. In this way we were able to successfully apply the spectral clustering algorithm to the large training set of $300,000$ items unlike~\citet{Petkos:2012:SED:2324796.2324825} who also applied a spectral clustering technique to event detection, but on a comparatively small sample size.
% subsection event_clustering (end)

% section methodology (end)

\section{Experiments} % (fold)
\label{sec:experiments}

For the runs submitted we first had to explore and set the various parameters of our approach against the training set. Our first parameter was the weightings with which the feature affinity matrices were combined. We performed a search across the weighting simplex and found that for the training set the best F1 score was achieved when the features were weighted as: $p_{timetaken}=3$, $p_{timeposted}=0$, $p_{geolocation}=1$, $p_{description}=1$, $p_{tags}=3$, $p_{title}=0$. However, we noticed that the F1 achieved by the top feature weightings on the simplex were very similar. Therefore, to avoid over-fitting we selected the top 1000 F1 ranked selections on the weightings simplex and got the weightings average in the training set. This resulted in the features weighted as: $p_{timetaken}=2.1$, $p_{timeposted}=1.8$, $p_{geolocation}=1.4$, $p_{description}=0.7$, $p_{tags}=1.7$, $p_{title}=0.3$. We performed a similar line search to find the optimal values for DBSCAN's parameters ($eps=0.45$, $minpts=3$) and Spectral Clustering's parameters ($eigengap=0.8$, $eps=-0.6$). The 4 runs we submitted for the MediaEval 2013 SED Task 1 were therefore: DBSCAN with the best weighting, Spectral clustering with the best, DBSCAN with the average weighting and spectral clustering with the average. All these runs were performed using our incremental clustering technique.
% section experiments (end)


\bibliographystyle{plainnat}
\bibliography{../bibliography}
\end{document}
